# âœ¨ Abracadabra â€“ Speak Your Vision Into Reality  

> **Abracadabra** is a new **vision schema language** â€“ a simple way to describe and run *experiential scenes* (lights, sound, screen, vibration, IoT).  
> Think of it as **HTML for experiences**: from text â†’ to living, multi-sensory reality.  

---

## ğŸŒŸ Why Abracadabra?
- ğŸª„ **Simple**: Write what you imagine, run it anywhere.  
- ğŸŒ **Universal**: A shared schema for XR, IoT, Smart Homes, Events.  
- ğŸ”Œ **Interoperable**: Works with LLMs, MCP, and any API/Adapter.  
- ğŸ“¦ **Extensible**: Developers can add their own adapters.  

---

## ğŸ“œ Vision Schema (v0.1)
Core format is **JSON-based**:

```json
{
  "version": "abra-0.1.0",
  "intent": "welcome ceremony",
  "bind": {
    "lights": { "type": "light_group", "id": "main" },
    "sound":  { "type": "audio", "src": "intro.wav" },
    "screen": { "type": "screen", "id": "stage" }
  },
  "scene": {
    "flow": [
      { "do": [ { "lighting": { "ref": "main", "preset": "dim-blue" } } ] },
      { "after": "2s", "do": [ { "audio": { "ref": "sound", "play": true } } ] },
      { "after": "5s", "do": [ { "screen": { "ref": "stage", "show": "WELCOME" } } ] }
    ]
  }
}
### ğŸŒŸ Examples

```json
{
  "version": "abra-0.1.0",
  "intent": "welcome ceremony",
  "scene": { "flow": [ ... ] }
}
